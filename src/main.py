# -*- coding: utf-8 -*-
"""main.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1rudoZhTfUXXPAHenjOL1_vILzBxJ4MOw
"""

import numpy as np
import pandas as pd
import os
import tensorflow as tf
import keras
from keras import Model
from keras.applications.densenet import DenseNet121
from keras.applications import VGG16
from keras.preprocessing import image
from keras.applications.densenet import preprocess_input, decode_predictions
import io
from PIL import Image
from keras.layers import GlobalMaxPooling2D
import random
import matplotlib.pyplot as plt
import matplotlib.image as mpimg
import cv2
import pathlib
from sklearn.metrics.pairwise import linear_kernel
from sklearn.neighbors import NearestNeighbors
import pickle
import urllib.request
from sklearn.ensemble import RandomForestRegressor
from sklearn.metrics import mean_squared_error
from sklearn.model_selection import train_test_split

"""Datasets Required in this are:

1. Fashion Dataset
2. Test Image/ URL
3. All images path
4. Embeddings file
5. tokenized trends Dataset
6. Tokenized Description dataset
"""

df_tokenize = pd.read_csv('/content/tokenized_dataset.csv')

df_tokenize['num_purchases'] = df_tokenize['units_sold']  # Assuming 'units_sold' represents the number of purchases
most_purchased_items = df_tokenize.groupby('title_orig')['num_purchases'].sum().sort_values(ascending=False)

df_tokenize['total_sales'] = df_tokenize['retail_price'] * df_tokenize['units_sold']

grouped_data = df_tokenize.groupby('product_id').agg({
    'total_sales': 'sum',
    'units_sold': 'sum',
    'rating': 'mean',
    'title_orig_tokenized': 'first'  # Assuming title_orig_tokenised is consistent for each product_id
}).reset_index()

# Define features and target
X = grouped_data[['total_sales', 'rating']]
y = grouped_data['units_sold']

# Split the data
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Initialize the model
model = RandomForestRegressor(n_estimators=100, random_state=42)
# Train the model
model.fit(X_train, y_train)
# Predict on the test set
y_pred = model.predict(X_test)
# Calculate the error
mse = mean_squared_error(y_test, y_pred)
print(f'Mean Squared Error: {mse}')
# Predict future purchases
future_predictions = model.predict(X)

# Add predictions to the original data
grouped_data['predicted_units_sold'] = future_predictions

# Sort by predicted units sold to identify top trends
top_trends = grouped_data.sort_values(by='predicted_units_sold', ascending=False).head(10)

# Display top trends with title_orig_tokenised
print("Top Trends:")
print(top_trends[['title_orig_tokenized', 'predicted_units_sold']])

top_trends

test_df = set()

def identify_style(top_trends, styles_df):
    for idx, i in (enumerate(top_trends['title_orig_tokenized'])):
        count = 0
        for j in styles_df['description_tokenized']:
            for k in i:
                if(j in k):
                    count+=1

        if(count >= 5):
            test_df.add(styles_df[idx])
            print(test_df)

    return test_df

path = "/content/drive/MyDrive/trend_dataset/train_images/"

with open('df_embeddings.pkl','rb') as f :
        df_embeddings = pickle.load(f)

print(df_embeddings.shape)
df_embeddings.head()

def predict_img(model, path, img_name):
    print("predict_img function started")
    img = image.load_img(path+str(img_name), target_size = (224,224))
    img = image.img_to_array(img)
    img = np.expand_dims(img, axis = 0)
    img = preprocess_input(img)
    print("predict_img function accessed")
    return model.predict(img)

def get_similarity(model, path, test_image, df_embeddings):
    #test_image should be the image that need to be compared
    print("get_similarity function started")
    sample_image = predict_img(model,path, test_image)

    neighbors = NearestNeighbors(n_neighbors = 10, algorithm='brute' ,metric = 'euclidean')
    neighbors.fit(df_embeddings)
    distance, indices = neighbors.kneighbors(sample_image)
    print(indices)
    print("get_similarity function accessed")
    return indices

def test(img, path, vgg16_model, df_embeddings, styles_df):
    print("test function started")
    url = path + str(img)
    a = plt.imread(url)
    plt.imshow(a)
    sample_image = predict_img(vgg16_model, path, img)
    df_sample_image = pd.DataFrame(sample_image)
    indices = get_similarity(vgg16_model, path, img, df_embeddings)
    recommendation = [i for i in indices]
    # recommendation_list = recommendation.to_list()
    j=0
    for img in recommendation[0]:
      plt.figure(figsize = (20,20))
      plt.subplot(6,10, j+1)
      cloth_img = mpimg.imread(path+ str(img) + '.jpg')
      plt.imshow(cloth_img)
      plt.axis('off')
      j+=1

    plt.title("Recommended Images", loc = 'left')
    plt.subplots_adjust(wspace=0.5, hspace=1)
    plt.show()
    print("test function accessed")

def main():
    print("main function started")
    dataset_path = pathlib.Path(path)
    dirs_names = os.listdir(dataset_path)
    print(dirs_names)

    styles_df = pd.read_csv('Fashion Dataset.csv')

    #Modeling and Get image embeddings
    vgg16 = VGG16(include_top = False, weights='imagenet', input_shape=(224,224,3))
    vgg16.trainable = False
    vgg16_model = keras.Sequential([vgg16, GlobalMaxPooling2D()])
    vgg16_model.summary()

    styles_df = pd.read_csv('Fashion Dataset.csv')

    ch = input("Do you have any reference image to upload (yes/no) : ")
    if(ch == "yes"):
      img = input("Enter the image URL : ")
      img = downloadImage(img)
      test(img, path, vgg16_model, df_embeddings, test_df)
    else:
      test_image = "88" + ".jpg"
      test(test_image, path, vgg16_model, df_embeddings, test_df)

def downloadImage(url):

    # Build the opener with custom headers
    req = urllib.request.build_opener()
    req.addheaders = [('User-Agent', 'Mozilla/5.0'), ('Accept', 'text/html')]
    urllib.request.install_opener(req)

    # Open the URL and read the image data
    with urllib.request.urlopen(url) as response:
        data = response.read()

    # Convert the image data to a file-like object
    img_bytes = io.BytesIO(data)

    # Load the image from the file-like object
    img = Image.open(img_bytes)
    img = img.resize((224, 224))
    filename = "/content/drive/MyDrive/trend_dataset/train_images/uploaded_test_img.jpg"
    Image.Image.save(img, filename)

    return "uploaded_test_img.jpg"

main()

!pip install flask

from flask import Flask, request, jsonify

app = Flask(__name__)

@app.route('/trends', methods=['POST'])
def identify_trends_endpoint():
    # Your trend identification code here
    trend = top_trends['title_orig_tokenized']
    print(trend)
    pass

@app.route('/recommendations', methods=['POST'])
def recommend_styles_endpoint():
    # Your trend recommendation code here

    pass

if __name__ == '__main__':
    app.run(debug=True, host='0.0.0.0', port=8080)